apiVersion: v1
data:
  nginx.conf: |
    worker_processes 5;  ## Default: 1
    error_log /dev/stderr;
    pid /tmp/nginx.pid;
    worker_rlimit_nofile 8192;

    events {
        worker_connections 6006;  ## Default: 1024
    }

    http {
        client_body_temp_path /tmp/client_temp;
        proxy_temp_path /tmp/proxy_temp_path;
        fastcgi_temp_path /tmp/fastcgi_temp;
        uwsgi_temp_path /tmp/uwsgi_temp;
        scgi_temp_path /tmp/scgi_temp;

        proxy_read_timeout 300;
        proxy_connect_timeout 300;
        proxy_send_timeout 300;

        default_type application/octet-stream;
        log_format main '$remote_addr - $remote_user [$time_local]  $status '
                        '"$request" $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for" [$http_x_boltx_cluster]';
        access_log /dev/stderr main;

        sendfile on;
        tcp_nopush on;
        resolver kube-dns.kube-system.svc.cluster.local;

        map "$remote_user:$http_user_agent" $block_agent {
            default 0;
            "boltx:Go-http-client/1.1" 1;
            "boltx:okhttp/4.12.0" 1;
        }

        # ðŸ†• CANARY CONTROL: Weight-based traffic splitting
        # Set $canary_weight to control percentage of traffic to edge enforcement
        # 0 = all direct to Mimir (bypass)
        # 10 = 10% through edge enforcement, 90% direct  
        # 50 = 50% through edge enforcement, 50% direct
        # 100 = all through edge enforcement
        map $request_id $canary_weight {
            default 10;  # Start with 10% canary traffic
        }

        # Random number generator for canary decision
        map $request_id $is_canary {
            ~.{0,}0$ 1;  # 10% traffic (last digit is 0)
            default 0;
        }

        # ðŸ†• UPSTREAM DEFINITIONS
        upstream mimir_direct {
            # Direct path to Mimir Distributor (original behavior)
            server distributor.mimir.svc.cluster.local:8080;
        }

        upstream mimir_via_edge_enforcement {
            # Through mimir-edge-enforcement Envoy proxy
            server mimir-envoy.mimir-edge-enforcement.svc.cluster.local:8080;
        }

        server {
            listen 8080;
            auth_basic "Mimir";
            proxy_set_header X-Scope-OrgID $remote_user;
            auth_basic_user_file /etc/nginx/secrets/.htpasswd;

            # ðŸ†• Add canary headers for observability
            proxy_set_header X-Canary-Route $is_canary;
            proxy_set_header X-Original-URI $request_uri;

            location = / {
                return 200 'OK';
                auth_basic off;
            }

            # ðŸ†• CANARY TRAFFIC SPLITTING FOR METRICS INGESTION
            # This is where the magic happens - split /api/v1/push traffic
            location = /api/v1/push {
                # Enable request buffering for mirror functionality
                proxy_request_buffering on;

                # ðŸŽ¯ CANARY DECISION: Route based on percentage
                if ($is_canary) {
                    # Route through edge enforcement (with rate limiting)
                    proxy_pass http://mimir_via_edge_enforcement$request_uri;
                    break;
                }

                # Default: Direct to Mimir (original path)
                proxy_pass http://mimir_direct$request_uri;

                # ðŸ“Š OPTIONAL: Mirror traffic to edge enforcement for testing
                # Uncomment to shadow all traffic (non-blocking)
                # mirror /mirror_to_edge_enforcement;
                # mirror_request_body on;
            }

            # ðŸ†• MIRROR ENDPOINT (for shadow testing)
            location = /mirror_to_edge_enforcement {
                internal;
                proxy_pass http://mimir_via_edge_enforcement/api/v1/push;
                proxy_pass_request_body on;
                proxy_set_header X-Mirror-Request "true";
            }

            # ðŸ†• EMERGENCY BYPASS: Direct route bypassing edge enforcement
            location = /api/v1/push/direct {
                # Emergency route for instant rollback
                rewrite ^/api/v1/push/direct$ /api/v1/push break;
                proxy_pass http://mimir_direct;
            }

            # ðŸ†• DISTRIBUTOR ENDPOINTS - Route through edge enforcement for canary
            location /distributor {
                if ($is_canary) {
                    proxy_pass http://mimir_via_edge_enforcement$request_uri;
                    break;
                }
                proxy_pass http://mimir_direct$request_uri;
            }

            # Runtime config - always direct (no rate limiting needed)
            location /runtime_config {
                proxy_pass http://distributor.mimir.svc.cluster.local:8080$request_uri;
            }

            location ~ /service/([^/]+)/ {
                proxy_pass http://$1.mimir.svc.cluster.local:8080/$2;
            }

            # Zone Ingesters Router - always direct
            location ~ /status/ingester-zone-(.*)/(.*) {
                proxy_pass http://ingester-zone-$1.mimir.svc.cluster.local:8080/ingester/$2;
            }
            location ~ /status/store-gateway-zone-(.*)/(.*) {
                proxy_pass http://store-gateway-zone-$1.mimir.svc.cluster.local:8080/store-gateway/$2;
            }

            # Alertmanager endpoints - always direct (no rate limiting needed)
            location /alertmanager {
                proxy_pass http://alertmanager.mimir.svc.cluster.local:8080$request_uri;
            }
            location = /multitenant_alertmanager/status {
                proxy_pass http://alertmanager.mimir.svc.cluster.local:8080$request_uri;
            }
            location = /api/v1/alerts {
                proxy_pass http://alertmanager.mimir.svc.cluster.local:8080$request_uri;
            }

            # Ruler endpoints - always direct (no rate limiting needed)
            location /prometheus/config/v1/rules {
                proxy_pass http://ruler.mimir.svc.cluster.local:8080$request_uri;
            }
            location /prometheus/api/v1/rules {
                proxy_pass http://ruler.mimir.svc.cluster.local:8080$request_uri;
            }
            location = /api/v1/rules {
                proxy_pass http://ruler.mimir.svc.cluster.local:8080$request_uri;
            }
            location /prometheus/api/v1/rules {
                proxy_pass http://ruler.mimir.svc.cluster.local:8080$request_uri;
            }
            location = /prometheus/rules {
                proxy_pass http://ruler.mimir.svc.cluster.local:8080$request_uri;
            }
            location = /ruler/ring {
                proxy_pass http://ruler.mimir.svc.cluster.local:8080$request_uri;
            }
            location = /ruler/rule_groups {
                proxy_pass http://ruler.mimir.svc.cluster.local:8080$request_uri;
            }

            # Rest of /prometheus goes to the query frontend - always direct
            location /prometheus {
                if ($block_agent) {
                    return 403;
                }
                proxy_pass http://query-frontend.mimir.svc.cluster.local:8080$request_uri;
            }
        }
    }
kind: ConfigMap
metadata:
  name: mimir-nginx-canary
  namespace: mimir
