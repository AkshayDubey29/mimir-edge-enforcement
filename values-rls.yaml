# RLS (Rate Limit Service) Values - Production Configuration
# Use this file for deploying RLS in production with optimized settings

# Service configuration
service:
  type: ClusterIP
  port: 8082  # Main service port (admin API)
  ports:
    extAuthz: 8080  # DISABLED - not used
    rateLimit: 8081
    admin: 8082     # Main HTTP endpoint for remote write
    metrics: 9090

# Tenant identification
tenantHeader: "X-Scope-OrgID"

# Server configuration
server:
  enableExtAuthz: false  # Disable ext-authz server (use admin port for HTTP requests)
  enableRateLimit: true  # Enable rate limit server
  enableAdmin: true      # Enable admin server (HTTP endpoint)
  enableMetrics: true    # Enable metrics server

# Limits configuration - PRODUCTION HIGH SCALE
limits:
  maxRequestBytes: 52428800    # 50 MiB - Production: Increased for 5M series
  maxBodyBytes: 52428800       # 50 MiB - Production: Maximum body size per request
  failureModeAllow: true       # Production: Allow requests when parsing fails
  defaultSamplesPerSecond: 10000     # 10K samples/sec - Production: Increased for 5M series
  defaultBurstPercent: 50      # 50% burst allowance - Production: More burst capacity
  enforceBodyParsing: true     # Production: Enable body parsing for cardinality analysis
  defaultMaxLabelsPerSeries: 20      # Production: Increased label limit
  defaultMaxLabelValueLength: 4096   # Production: Increased label value length
  defaultMaxSeriesPerRequest: 100000 # Production: 100K series per request for 5M total

# Enforcement Configuration - Production Ready
enforcement:
  enabled: true
  # Cardinality limits - ENABLED
  enforceMaxSeriesPerRequest: true   # per_user_series_limit
  enforceMaxSeriesPerMetric: true    # per_metric_series_limit
  enforceMaxLabelsPerSeries: true    # per_labels_per_series_limit
  # Rate limiting - ENABLED
  enforceSamplesPerSecond: true      # Enable ingestion rate limiting
  enforceBytesPerSecond: false       # ‚ö†Ô∏è DISABLED: Current implementation uses MaxBodyBytes as rate limit (too restrictive)
  # Body size - ENABLED
  enforceMaxBodyBytes: true          # Enable body size enforcement

# üîß NEW: New series leniency configuration
newTenantLeniency: true  # Enable lenient limits (50%) when adding new series to prevent false positives

# üîß NEW: Selective filtering configuration
selectiveFiltering:
  enabled: true  # Enable selective filtering instead of binary allow/deny
  fallbackToDeny: true  # Fall back to deny if filtering fails
  seriesSelectionStrategy: "random"  # Strategy: random, oldest, newest, priority
  metricPriority:  # Priority order for metrics (higher priority = dropped last)
    - "critical_metrics"
    - "important_metrics" 
    - "standard_metrics"
  maxFilteringPercentage: 50  # Don't filter more than 50% of request
  minSeriesToKeep: 10  # Always keep at least 10 series

# Store configuration
store:
  backend: "memory"  # TEMPORARILY USING MEMORY - Use Redis for production (shared state across pods)

# Redis configuration for external Redis service
redis:
  enabled: true
  mode: "external"  # Use external Redis service
  external:
    address: "redis-shared-service.redis-shared.svc.cluster.local:6379"

# Mimir configuration for direct integration
mimir:
  host: "mimir-distributor.mimir.svc.cluster.local"
  port: "8080"

# Logging configuration - PRODUCTION OPTIMIZED
log:
  level: "info"  # Production logging level
  enableGRPCLogs: false  # Disable gRPC logs for performance
  enableDetailedLogs: false  # Disable detailed logs for performance

# Health check configuration - More lenient for Kind cluster
healthCheck:
  livenessProbe:
    httpGet:
      path: /healthz
      port: admin
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    httpGet:
      path: /readyz
      port: admin
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 3

# Performance tuning - PRODUCTION HIGH SCALE
performance:
  # Request processing optimization
  maxConcurrentRequests: 10000   # Production: 10K concurrent requests for high scale
  requestTimeout: "60s"          # Production: Increased timeout for large payloads
  bodyParseTimeout: "20s"        # Production: Increased timeout for 5M series parsing
  
  # Redis connection optimization (Production optimized)
  redisPoolSize: 200             # Production: Larger pool for 40 pods
  redisMinIdleConns: 50          # Production: More idle connections
  redisMaxRetries: 5             # Production: More retries for reliability
  redisConnectTimeout: "2s"      # Production: Increased connection timeout
  redisReadTimeout: "5s"         # Production: Increased read timeout
  redisWriteTimeout: "5s"        # Production: Increased write timeout
  
  # Memory optimization
  enableMemoryOptimization: true # Enable memory-efficient processing
  maxRequestBodySize: "50MB"     # Production: Maximum request body size
  enableRequestPooling: true     # Enable request object pooling
  enableMetricsOptimization: true # Optimize metrics collection
  
  # Circuit breaker settings (Production)
  circuitBreakerEnabled: true    # Enable circuit breaker for reliability
  circuitBreakerThreshold: 5     # Failure threshold
  circuitBreakerTimeout: "30s"   # Recovery timeout

# Deployment configuration - PRODUCTION HIGH SCALE
replicaCount: 10  # Production: Start with 10 replicas

image:
  repository: ghcr.io/akshaydubey29/mimir-rls
  tag: "latest"  # Latest version with scientific notation support and multi-arch builds
  pullPolicy: IfNotPresent  # Production: Use IfNotPresent for efficiency

# Resource configuration - PRODUCTION HIGH SCALE
resources:
  limits:
    cpu: 4000m    # Production: 4 cores for high scale processing
    memory: 16Gi  # Production: 16GB memory limit for large payloads
  requests:
    cpu: 1000m    # Production: 1 core minimum
    memory: 8Gi   # Production: 8GB memory request for high scale

# Security context
securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
      - ALL

# Horizontal Pod Autoscaler - PRODUCTION HIGH SCALE
hpa:
  enabled: true
  minReplicas: 10    # Production: Minimum 10 replicas for high availability
  maxReplicas: 40    # Production: Maximum 40 replicas for peak load
  targetCPUUtilizationPercentage: 60    # Production: Lower threshold for faster scaling
  targetMemoryUtilizationPercentage: 60 # Production: Lower threshold for faster scaling

# Pod Disruption Budget - PRODUCTION HIGH SCALE
pdb:
  enabled: true
  minAvailable: 5  # Production: Ensure at least 5 pods available during disruptions

# Service Account
serviceAccount:
  create: true
  annotations: {}

# Pod annotations - Production
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9090"
  prometheus.io/path: "/metrics"

# Node selector
nodeSelector: {}

# Tolerations
tolerations: []

# Affinity - Production ready
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - mimir-rls
        topologyKey: kubernetes.io/hostname

# Service Monitor for Prometheus - Production
serviceMonitor:
  enabled: false  # Disable ServiceMonitor to avoid CRD issues
  scrapeTimeout: 10s
  labels: {}
  annotations: {}

# Liveness and readiness probes - PRODUCTION OPTIMIZED
livenessProbe:
  httpGet:
    path: /readyz
    port: admin
  initialDelaySeconds: 60  # Production: Longer initial delay for large pods
  periodSeconds: 30        # Production: Less frequent checks to reduce overhead
  timeoutSeconds: 10       # Production: Longer timeout for health checks
  failureThreshold: 5      # Production: More failures before restart

readinessProbe:
  httpGet:
    path: /readyz
    port: admin
  initialDelaySeconds: 30  # Production: Longer initial delay
  periodSeconds: 15        # Production: More frequent readiness checks
  timeoutSeconds: 8        # Production: Longer timeout
  failureThreshold: 3      # Production: Fewer failures before marking not ready
  successThreshold: 2      # Production: Require 2 successful checks before ready

# Startup probe - PRODUCTION OPTIMIZED
startupProbe:
  httpGet:
    path: /readyz
    port: admin
  initialDelaySeconds: 30  # Production: Longer initial delay
  periodSeconds: 15        # Production: Less frequent during startup
  timeoutSeconds: 10       # Production: Longer timeout during startup
  failureThreshold: 30     # Production: 7.5 minutes total startup time
